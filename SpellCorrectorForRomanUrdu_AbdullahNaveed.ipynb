{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "published-roberts",
   "metadata": {},
   "source": [
    "Abdullah Naveed i180654@nu.edu.pk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-delay",
   "metadata": {},
   "source": [
    "# Spell Correction for Roman Urdu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-insured",
   "metadata": {},
   "source": [
    "## Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "short-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "enlp = English()\n",
    "tokenizer = enlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hourly-helping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Corpus Sentences:  4652818\n",
      "Sample:  academy of urdu literature canada ne bhi unhe mein award diya\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "#Reading From Corpus file\n",
    "file1 = open('data.txt', 'r')\n",
    "corpusLines = file1.readlines()\n",
    "\n",
    "# Save the text in List\n",
    "for line in corpusLines:\n",
    "    if(line != '\\n'):\n",
    "        corpus.append(line.strip())\n",
    "    \n",
    "        \n",
    "# Testing\n",
    "print(\"Length of Corpus Sentences: \", len(corpus))\n",
    "print(\"Sample: \", corpus[532])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supported-compilation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Corpus Words:  63308818\n",
      "Sample:  gai\n"
     ]
    }
   ],
   "source": [
    "corpusWords = []\n",
    "\n",
    "# Tokenizing corpus into a list of words\n",
    "for line in corpus:\n",
    "    if(line != '\\n'):\n",
    "        sentence = tokenizer(line)\n",
    "        \n",
    "        for word in sentence:\n",
    "            if(word.text != \"\\t\" and word.text != \"\\n\"):\n",
    "                corpusWords.append(word.text)\n",
    "                \n",
    "# Testing\n",
    "print(\"Length of Corpus Words: \", len(corpusWords))\n",
    "print(\"Sample: \", corpusWords[532])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "organized-result",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Misspelled Words:  36101\n",
      "Sample:\n",
      "['Correct', 'Wrong']\n",
      "['ka', 'kaz', 'cka', 'mka', 'kga', 'yka', 'kba']\n"
     ]
    }
   ],
   "source": [
    "misspelledWords = []\n",
    "\n",
    "#Reading From MisspelledWords file\n",
    "file2 = open('misspellings.txt', 'r')\n",
    "misspelledLines = file2.readlines()\n",
    "\n",
    "# Tokenizing the words and saving in List\n",
    "sentenceCounter = 0\n",
    "for line in misspelledLines:\n",
    "    if(line != '\\n'):\n",
    "        sentence = tokenizer(line)\n",
    "        \n",
    "        for index, word in enumerate(sentence):\n",
    "            if(index == 0):\n",
    "                misspelledWords.append([word.text])\n",
    "                \n",
    "            if(index > 1):\n",
    "                if(word.text != \"\\t\" and word.text != \"\\n\"):\n",
    "                    misspelledWords[sentenceCounter].append(word.text)\n",
    "                \n",
    "        sentenceCounter += 1\n",
    "        \n",
    "\n",
    "# Testing\n",
    "print(\"Length of Misspelled Words: \", len(misspelledWords))\n",
    "print(\"Sample:\")\n",
    "print(misspelledWords[0])\n",
    "print(misspelledWords[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-canon",
   "metadata": {},
   "source": [
    "# Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-sally",
   "metadata": {},
   "source": [
    "### UNI-GRAM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepted-authority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of UNIGRAM:  35777\n",
      "Sample:  2.503600683241314e-05\n"
     ]
    }
   ],
   "source": [
    "unigrams = {}\n",
    "\n",
    "# Formula of UNIGRAM: P(wi) = count(wi) / count(total number of words)\n",
    "\n",
    "totalNumberOfWords = len(corpusWords)\n",
    "unigramsCount = {}\n",
    "\n",
    "# Getting Count for each word\n",
    "for word in corpusWords:\n",
    "    \n",
    "    if word not in unigramsCount:\n",
    "        unigramsCount[word] = 1\n",
    "    else:\n",
    "        unigramsCount[word] += 1\n",
    "\n",
    "# Counting unigram probabilities\n",
    "for word in unigramsCount:\n",
    "    \n",
    "    wordProbability = unigramsCount[word] / totalNumberOfWords\n",
    "    unigrams[word] = wordProbability\n",
    "\n",
    "# Testing\n",
    "print(\"Length of UNIGRAM: \", len(unigrams))\n",
    "print(\"Sample: \", unigrams[\"sai\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-testament",
   "metadata": {},
   "source": [
    "## Saving and Loading Models & Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrow-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "\n",
    "# Saving models as json to avoid computation for later use.\n",
    "#with open('JSON_DATA/UnigramModel.json', 'w') as f:\n",
    "    #json.dump(unigrams,f)\n",
    "    \n",
    "# Other Data (to avoid reading and tokenization time)\n",
    "\n",
    "#with open('JSON_DATA/corpus.json', 'w') as f:\n",
    "    #json.dump(corpus,f)\n",
    "    \n",
    "#with open('JSON_DATA/corpusWords.json', 'w') as f:\n",
    "    #json.dump(corpusWords,f)\n",
    "    \n",
    "#with open('JSON_DATA/misspelledWords.json', 'w') as f:\n",
    "    #json.dump(misspelledWords,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reverse-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "\n",
    "# Loading models for use.\n",
    "#with open('JSON_DATA/UnigramModel.json') as f:\n",
    "    #unigrams = [tuple(x) for x in json.load(f)]\n",
    "    \n",
    "# Other Data\n",
    "\n",
    "#with open('JSON_DATA/corpus.json') as f:\n",
    "    #corpus = [(x) for x in json.load(f)]\n",
    "    \n",
    "#with open('JSON_DATA/corpusWords.json') as f:\n",
    "    #corpusWords = [(x) for x in json.load(f)]\n",
    "    \n",
    "#with open('JSON_DATA/misspelledWords.json') as f:\n",
    "    #misspelledWords = [(x) for x in json.load(f)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4482809",
   "metadata": {},
   "source": [
    "### For Error Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2997746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted:  sai into:\n",
      "sa\n",
      "ai\n"
     ]
    }
   ],
   "source": [
    "# Generating Bigrams\n",
    "\n",
    "bigrams = []\n",
    "unigramsForErrorModel = []\n",
    "totalWords = set(corpusWords)\n",
    "\n",
    "for index, row in enumerate(corpusWords):\n",
    "    \n",
    "    for letterNumber in range(0, len(row)-1):\n",
    "        \n",
    "        bigrams.append(row[letterNumber]+row[letterNumber+1])\n",
    "        \n",
    "        unigramsForErrorModel.append(row[letterNumber])\n",
    "        if(letterNumber == len(row)-1):\n",
    "            unigramsForErrorModel.append(row[letterNumber+1])\n",
    "\n",
    "#Testing\n",
    "print(\"Converted: \", corpusWords[0], \"into:\")\n",
    "print(bigrams[0])\n",
    "print(bigrams[1])\n",
    "\n",
    "bigramsCount = {}\n",
    "unigramsCountForErrorModel = {}\n",
    "\n",
    "# Getting Count for each word\n",
    "for word in bigrams:\n",
    "    \n",
    "    if word not in bigramsCount:\n",
    "        bigramsCount[word] = 1\n",
    "    else:\n",
    "        bigramsCount[word] += 1\n",
    "        \n",
    "# Getting Count for each word\n",
    "for word in unigramsForErrorModel:\n",
    "    \n",
    "    if word not in unigramsCountForErrorModel:\n",
    "        unigramsCountForErrorModel[word] = 1\n",
    "    else:\n",
    "        unigramsCountForErrorModel[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75fc7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some Cleaning\n",
    "bigrams.clear()\n",
    "unigramsForErrorModel.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b6eb8e",
   "metadata": {},
   "source": [
    "## Pretty Tables Printings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "538c11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prettytable\n",
    "\n",
    "# For Confusion Matrices\n",
    "def print_confusionMatrix(confusionMatrix):\n",
    "    \n",
    "    tableCourses = prettytable.PrettyTable()\n",
    "    tableCourses.field_names  = ['#','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "    tableCourses._max_width = {'#':1,'a':1,'b':1,'c':1,'d':1,'e':1,'f':1,'g':1,'h':1,'i':1,'j':1,'k':1,'l':1,'m':1,'n':1,'o':1,'p':1,'q':1,'r':1,'s':1,'t':1,'u':1,'v':1,'w':1,'x':1,'y':1,'z':1}\n",
    "    counter = 0\n",
    "    for rowCount,row in enumerate(confusionMatrix):\n",
    "        \n",
    "        if(rowCount > 0):\n",
    "            items = []\n",
    "            spaces = []\n",
    "            for itemCount, item in enumerate(row):\n",
    "                items.append(item)\n",
    "                spaces.append(\" \")\n",
    "\n",
    "            tableCourses.add_row(items)\n",
    "            tableCourses.add_row(spaces)\n",
    "            counter += 1\n",
    "        \n",
    "    print(tableCourses)\n",
    "    \n",
    "\n",
    "# For Selection Model\n",
    "def print_SelectionModel(candidateWords, wrongCharacters, correctCharacters, candidateProbabilityFromErrorModel, candidateProbabilityFromLanguageModel, candidateFinalProbability):\n",
    "    \n",
    "    tableCourses = prettytable.PrettyTable()\n",
    "    tableCourses.field_names  = ['Candidates','x|w','P(x|w)','P(w)','P(x|w)*P(w) *10^9']\n",
    "\n",
    "    for rowCount,row in enumerate(candidateWords):\n",
    "        items = []\n",
    "        \n",
    "        items.append(row)\n",
    "        items.append(wrongCharacters[rowCount] + \"|\" + correctCharacters[rowCount])\n",
    "        items.append(candidateProbabilityFromErrorModel[rowCount])\n",
    "        items.append(candidateProbabilityFromLanguageModel[rowCount])\n",
    "        items.append(candidateFinalProbability[rowCount])\n",
    "\n",
    "        tableCourses.add_row(items)\n",
    "        \n",
    "    print(tableCourses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-point",
   "metadata": {},
   "source": [
    "## Generating Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "embedded-enclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# a b c d e f g h i j k l m n o p q r s t u v w x y z \n",
      "a 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "b 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "c 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "d 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "e 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "f 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "g 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "h 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "i 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "j 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "k 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "l 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "m 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "o 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "p 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "q 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "r 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "s 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "t 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "u 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "v 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "w 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "x 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "y 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "z 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    }
   ],
   "source": [
    "# Initializing Confusion Matrices\n",
    "import copy\n",
    "alphabets = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "insertionMatrix = []\n",
    "deletionMatrix = []\n",
    "substitutionMatrix = []\n",
    "transpositionMatrix = []\n",
    "\n",
    "# Generating 27*27 Confusion Matrices\n",
    "for index in range(0,26):\n",
    "    if(index == 0):\n",
    "        insertionMatrix.append([\"#\"] + copy.deepcopy(alphabets))\n",
    "        deletionMatrix.append([\"#\"] + copy.deepcopy(alphabets))\n",
    "        substitutionMatrix.append([\"#\"] + copy.deepcopy(alphabets))\n",
    "        transpositionMatrix.append([\"#\"] + copy.deepcopy(alphabets))\n",
    "        \n",
    "    insertionMatrix.append(copy.deepcopy(alphabets) + [\"0\"])\n",
    "    deletionMatrix.append(copy.deepcopy(alphabets) + [\"0\"])\n",
    "    substitutionMatrix.append(copy.deepcopy(alphabets) + [\"0\"])\n",
    "    transpositionMatrix.append(copy.deepcopy(alphabets) + [\"0\"])\n",
    "    \n",
    "tempAlphabets = copy.deepcopy(alphabets)\n",
    "for index in range(0, 26):\n",
    "    insertionMatrix[index+1][0] = tempAlphabets[index]\n",
    "    deletionMatrix[index+1][0] = tempAlphabets[index]\n",
    "    substitutionMatrix[index+1][0] = tempAlphabets[index]\n",
    "    transpositionMatrix[index+1][0] = tempAlphabets[index]\n",
    "\n",
    "# Changing inside values to zeros for later update\n",
    "for indexOfRow, row in enumerate(insertionMatrix):\n",
    "    for indexOfCol, col in enumerate(row):\n",
    "        \n",
    "        if(indexOfRow == 0 and indexOfCol == 0):\n",
    "            insertionMatrix[indexOfRow][indexOfCol] = \"#\"\n",
    "            deletionMatrix[indexOfRow][indexOfCol] = \"#\"\n",
    "            substitutionMatrix[indexOfRow][indexOfCol] = \"#\"\n",
    "            transpositionMatrix[indexOfRow][indexOfCol] = \"#\"\n",
    "        \n",
    "        if(indexOfRow > 0 and indexOfCol > 0):\n",
    "            insertionMatrix[indexOfRow][indexOfCol] = 0\n",
    "            deletionMatrix[indexOfRow][indexOfCol] = 0\n",
    "            substitutionMatrix[indexOfRow][indexOfCol] = 0\n",
    "            transpositionMatrix[indexOfRow][indexOfCol] = 0\n",
    "            \n",
    "# Testing\n",
    "for row in transpositionMatrix:\n",
    "    for item in row:\n",
    "        print(item, end= \" \")\n",
    "    print()\n",
    "    \n",
    "#print(alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "featured-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def change_item_string(string, new_character, position):\n",
    "    string = string[:position] + new_character + string[position+1:]\n",
    "    return string\n",
    "\n",
    "def add_item_string(string, new_character, position):\n",
    "    string = string[:position] + new_character + string[position:]\n",
    "    return string\n",
    "\n",
    "def remove_item_string(string, position):\n",
    "    string = string[:position] + string[position+1:]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "shaped-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Confusion Matrices\n",
    "\n",
    "def find_edit_type(correctWord, wrongWord):\n",
    "    \n",
    "    #To store type         // 0: insertion, 1: deletion, 2: substitution, 3: Transposition\n",
    "    editType = [False]*4\n",
    "    \n",
    "    wi = \"\"\n",
    "    xi = \"\"\n",
    "    \n",
    "    # If both words are of equal length\n",
    "    if(len(correctWord) == len(wrongWord)):\n",
    "        \n",
    "        for index in range(0, len(correctWord)):\n",
    "            \n",
    "            # If an alphabet doesn't match\n",
    "            if(correctWord[index] != wrongWord[index]):\n",
    "                \n",
    "                #Now its either substituted or transposed\n",
    "                \n",
    "                # For Substitution:\n",
    "                tempWord = wrongWord\n",
    "                \n",
    "                tempWord = change_item_string(tempWord, correctWord[index], index)\n",
    "                \n",
    "                if(tempWord == correctWord):\n",
    "                    editType[2] = True\n",
    "                    wi = correctWord[index]\n",
    "                    xi = wrongWord[index]\n",
    "                    break\n",
    "                    \n",
    "                # For Transposition\n",
    "                tempWord = wrongWord\n",
    "                if(index < len(tempWord)-1):\n",
    "                    tempAlphabet = tempWord[index]\n",
    "                    tempWord = change_item_string(tempWord, tempWord[index+1], index)            \n",
    "                    tempWord = change_item_string(tempWord, tempAlphabet, index+1)\n",
    "\n",
    "                    if(tempWord == correctWord):\n",
    "                        editType[3] = True\n",
    "                        wi = wrongWord[index+1] + wrongWord[index]\n",
    "                        xi = wrongWord[index] + wrongWord[index+1]\n",
    "                        break\n",
    "                    \n",
    "    \n",
    "    # If both words are of different length\n",
    "    else:\n",
    "        \n",
    "        ## Checking for last alphabet\n",
    "        \n",
    "        # Check if alphabet inserted at the end\n",
    "        if(wrongWord[:len(wrongWord)-1] == correctWord):\n",
    "            editType[0] = True\n",
    "            wi = wrongWord[len(wrongWord)-2:len(wrongWord)-1]\n",
    "            xi = wrongWord[len(wrongWord)-1:len(wrongWord)]\n",
    "            #print(correctWord, \"misspelled as:\", wrongWord, \"by inserting:\", xi, \"after:\", wi)\n",
    "            return False, editType, wi, xi\n",
    "\n",
    "        # Check if alphabet deleted at the end\n",
    "        elif(correctWord[:len(correctWord)-1] == wrongWord):\n",
    "            editType[1] = True\n",
    "            wi = correctWord[len(correctWord)-2:len(correctWord)-1]\n",
    "            xi = correctWord[len(correctWord)-1:len(correctWord)]\n",
    "            #print(correctWord, \"misspelled as:\", wrongWord, \"by deleting:\", xi, \"after:\", wi)\n",
    "            return False, editType, wi, xi\n",
    "        \n",
    "        ## Checking before last alphabet\n",
    "        else:\n",
    "            shorterWordLength = min(len(correctWord), len(wrongWord))\n",
    "            \n",
    "            for index in range(0, shorterWordLength):\n",
    "\n",
    "                # If an alphabet doesn't match\n",
    "                if(correctWord[index] != wrongWord[index]):\n",
    "\n",
    "                    # For Deletion\n",
    "                    tempWord = wrongWord\n",
    "                    tempWord = add_item_string(tempWord, correctWord[index], index)\n",
    "\n",
    "                    if(tempWord == correctWord):\n",
    "                        editType[1] = True\n",
    "                        xi = correctWord[index]\n",
    "                        wi = wrongWord[index]\n",
    "                        break\n",
    "                        \n",
    "                    # For Insertion\n",
    "                    tempWord = wrongWord\n",
    "                    tempWord = remove_item_string(tempWord, index)\n",
    "\n",
    "                    if(tempWord == correctWord):\n",
    "                        editType[0] = True\n",
    "                        xi = wrongWord[index]\n",
    "                        wi = correctWord[index]\n",
    "                        break\n",
    "    \n",
    "    #Testing\n",
    "    #if(editType[0]):\n",
    "        #print(correctWord, \"misspelled as:\", wrongWord, \"by inserting:\", xi, \"before:\", wi)\n",
    "        \n",
    "    #elif(editType[1]):\n",
    "        #print(correctWord, \"misspelled as:\", wrongWord, \"by deleting:\", xi, \"before:\", wi)\n",
    "        \n",
    "    #elif(editType[2]):\n",
    "        #print(correctWord, \"misspelled as:\", wrongWord, \"by substituting:\", xi, \"instead of:\", wi)\n",
    "        \n",
    "    #elif(editType[3]):\n",
    "        #print(correctWord, \"misspelled as:\", wrongWord, \"by tranposition of:\", xi, \"with:\", wi)\n",
    "        \n",
    "    return True, editType, wi, xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fewer-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "#find_edit_type(\"hello\",\"htello\")\n",
    "#print()\n",
    "#find_edit_type(\"hello\",\"ello\")\n",
    "#print()\n",
    "#find_edit_type(\"hello\",\"herlo\")\n",
    "#print()\n",
    "#find_edit_type(\"hello\",\"helol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "plastic-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating tables for \"misspellings.txt\"\n",
    "\n",
    "# Here: Wrong word on Y-AXIS & Correct word on X-AXIS\n",
    "indexes = {'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26}\n",
    "\n",
    "for index, row in enumerate(misspelledWords):\n",
    "    \n",
    "    # First row is: \"Correct, Wrong\" so skipping it!\n",
    "    if(index == 0):\n",
    "        continue\n",
    "        \n",
    "    for wordNumber, word in enumerate(row):\n",
    "        \n",
    "        if(wordNumber > 0 and word != \",\"):\n",
    "            \n",
    "            # Check for error\n",
    "            errorBeforeEnd, editType, wi, xi = find_edit_type(row[0], word)\n",
    "            \n",
    "            if(errorBeforeEnd):\n",
    "                \n",
    "                #Insertion of xi before wi\n",
    "                if(editType[0]):\n",
    "                    \n",
    "                    Y_AXIS = indexes[wi]\n",
    "                    X_AXIS = indexes[xi]\n",
    "                    insertionMatrix[X_AXIS][Y_AXIS] += 1\n",
    "                    \n",
    "                #Deletion of xi before wi\n",
    "                elif(editType[1]):\n",
    "                    \n",
    "                    Y_AXIS = indexes[wi]\n",
    "                    X_AXIS = indexes[xi]\n",
    "                    deletionMatrix[X_AXIS][Y_AXIS] += 1\n",
    "                    \n",
    "                #Substitution of xi instead of wi\n",
    "                elif(editType[2]):\n",
    "                    \n",
    "                    Y_AXIS = indexes[wi]\n",
    "                    X_AXIS = indexes[xi]\n",
    "                    substitutionMatrix[X_AXIS][Y_AXIS] += 1\n",
    "                    \n",
    "                #Transposition of xi with wi\n",
    "                elif(editType[3]):\n",
    "    \n",
    "                    Y_AXIS = indexes[wi[0]]\n",
    "                    X_AXIS = indexes[xi[0]]\n",
    "                    transpositionMatrix[X_AXIS][Y_AXIS] += 1\n",
    "                    \n",
    "            else:\n",
    "                #Insertion of xi after wi\n",
    "                if(editType[0]):\n",
    "                    \n",
    "                    Y_AXIS = indexes[wi]\n",
    "                    X_AXIS = indexes[xi]\n",
    "                    insertionMatrix[X_AXIS][Y_AXIS] += 1\n",
    "                \n",
    "                #Deletion of xi after wi\n",
    "                elif(editType[1]):\n",
    "                    \n",
    "                    Y_AXIS = indexes[wi]\n",
    "                    X_AXIS = indexes[xi]\n",
    "                    deletionMatrix[X_AXIS][Y_AXIS] += 1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "scheduled-finnish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "| # | a | b | c | d | e | f | g | h | i | j | k | l | m | n | o | p | q | r | s | t | u | v | w | x | y | z |\n",
      "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "| a | 0 | 7 | 6 | 1 | 1 | 2 | 4 | 1 | 1 | 3 | 8 | 1 | 9 | 2 | 1 | 5 | 1 | 1 | 1 | 1 | 9 | 1 | 2 | 1 | 7 | 2 |\n",
      "|   |   | 8 | 6 | 1 | 8 | 8 | 8 | 8 | 9 | 2 | 1 | 3 | 2 | 0 | 2 | 9 | 5 | 9 | 4 | 5 | 9 | 7 | 9 |   | 3 | 6 |\n",
      "|   |   |   |   | 9 | 4 |   |   | 9 | 0 |   |   | 8 |   | 1 | 9 |   |   | 3 | 5 | 9 |   |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| b | 6 | 0 | 6 | 1 | 2 | 2 | 6 | 1 | 2 | 2 | 8 | 1 | 8 | 2 | 2 | 6 | 1 | 2 | 1 | 1 | 1 | 2 | 2 | 5 | 8 | 3 |\n",
      "|   | 4 |   | 5 | 1 | 4 | 4 | 1 | 9 | 5 | 5 | 8 | 3 | 9 | 3 | 0 | 0 | 5 | 1 | 7 | 8 | 0 | 3 | 8 |   | 5 | 1 |\n",
      "|   | 2 |   |   | 6 | 8 |   |   | 6 | 2 |   |   | 1 |   | 6 | 6 |   |   | 8 | 9 | 6 | 7 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| c | 6 | 7 | 0 | 1 | 2 | 3 | 7 | 2 | 2 | 3 | 9 | 1 | 1 | 2 | 1 | 5 | 1 | 2 | 1 | 1 | 1 | 1 | 3 | 4 | 9 | 3 |\n",
      "|   | 3 | 8 |   | 1 | 7 | 5 | 0 | 1 | 6 | 2 | 1 | 5 | 3 | 2 | 9 | 3 | 3 | 1 | 9 | 8 | 1 | 9 | 0 |   | 1 | 0 |\n",
      "|   | 4 |   |   | 5 | 3 |   |   | 6 | 5 |   |   | 0 | 0 | 6 | 3 |   |   | 0 | 3 | 3 | 8 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| d | 6 | 8 | 6 | 0 | 3 | 3 | 6 | 2 | 2 | 4 | 8 | 1 | 1 | 2 | 1 | 6 | 1 | 1 | 1 | 1 | 1 | 1 | 3 | 2 | 8 | 2 |\n",
      "|   | 3 | 4 | 8 |   | 0 | 7 | 9 | 0 | 4 | 0 | 8 | 1 | 1 | 4 | 6 | 3 | 7 | 8 | 4 | 7 | 1 | 7 | 0 |   | 2 | 2 |\n",
      "|   | 9 |   |   |   | 2 |   |   | 0 | 6 |   |   | 6 | 0 | 5 | 5 |   |   | 8 | 9 | 3 | 7 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| e | 5 | 7 | 6 | 1 | 0 | 3 | 6 | 2 | 2 | 4 | 1 | 1 | 1 | 2 | 1 | 5 | 1 | 2 | 1 | 1 | 9 | 1 | 2 | 4 | 7 | 2 |\n",
      "|   | 8 | 4 | 8 | 1 |   | 3 | 2 | 0 | 0 | 9 | 0 | 1 | 1 | 4 | 6 | 7 | 7 | 1 | 5 | 6 | 5 | 8 | 8 |   | 9 | 8 |\n",
      "|   | 0 |   |   | 0 |   |   |   | 6 | 8 |   | 8 | 1 | 1 | 1 | 1 |   |   | 4 | 6 | 4 |   |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| f | 6 | 7 | 6 | 1 | 2 | 0 | 7 | 2 | 2 | 4 | 9 | 1 | 1 | 2 | 1 | 7 | 1 | 2 | 1 | 1 | 9 | 1 | 4 | 5 | 8 | 2 |\n",
      "|   | 4 | 9 | 3 | 1 | 5 |   | 7 | 2 | 5 | 4 | 1 | 5 | 1 | 0 | 8 | 0 | 1 | 1 | 5 | 8 | 9 | 7 | 0 |   | 5 | 9 |\n",
      "|   | 4 |   |   | 7 | 5 |   |   | 7 | 3 |   |   | 7 | 2 | 0 | 3 |   |   | 7 | 6 | 8 |   |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| g | 6 | 7 | 6 | 8 | 2 | 3 | 0 | 1 | 2 | 4 | 1 | 1 | 1 | 2 | 1 | 5 | 1 | 2 | 1 | 1 | 1 | 1 | 3 | 3 | 8 | 2 |\n",
      "|   | 4 | 5 | 8 | 8 | 6 | 4 |   | 8 | 4 | 0 | 0 | 0 | 0 | 4 | 9 | 7 | 6 | 1 | 6 | 7 | 1 | 9 | 0 |   | 9 | 7 |\n",
      "|   | 1 |   |   |   | 0 |   |   | 7 | 7 |   | 8 | 5 | 2 | 2 | 3 |   |   | 2 | 0 | 9 | 8 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| h | 6 | 9 | 5 | 1 | 2 | 2 | 6 | 0 | 2 | 3 | 1 | 1 | 9 | 2 | 1 | 4 | 1 | 2 | 1 | 1 | 1 | 2 | 3 | 1 | 8 | 3 |\n",
      "|   | 1 | 1 | 9 | 0 | 4 | 8 | 1 |   | 6 | 0 | 0 | 2 | 0 | 2 | 5 | 3 | 5 | 0 | 4 | 7 | 1 | 6 | 9 | 0 | 3 | 6 |\n",
      "|   | 3 |   |   | 2 | 6 |   |   |   | 2 |   | 0 | 6 |   | 4 | 3 |   |   | 7 | 8 | 3 | 3 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| i | 5 | 7 | 5 | 9 | 2 | 3 | 5 | 1 | 0 | 3 | 1 | 1 | 1 | 2 | 1 | 5 | 1 | 1 | 1 | 1 | 9 | 1 | 3 | 3 | 7 | 2 |\n",
      "|   | 6 | 9 | 2 | 3 | 1 | 0 | 3 | 9 |   | 4 | 1 | 2 | 1 | 3 | 5 | 4 | 6 | 9 | 6 | 6 | 6 | 7 | 8 |   | 4 | 9 |\n",
      "|   | 0 |   |   |   | 2 |   |   | 9 |   |   | 0 | 8 | 4 | 8 | 0 |   |   | 1 | 4 | 0 |   |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| j | 6 | 8 | 5 | 1 | 2 | 3 | 7 | 1 | 2 | 0 | 9 | 1 | 1 | 2 | 2 | 6 | 1 | 2 | 1 | 1 | 1 | 1 | 3 | 4 | 9 | 3 |\n",
      "|   | 2 | 1 | 7 | 3 | 4 | 4 | 7 | 9 | 4 |   | 9 | 4 | 3 | 2 | 0 | 9 | 4 | 0 | 6 | 6 | 0 | 1 | 3 |   | 6 | 2 |\n",
      "|   | 7 |   |   | 8 | 0 |   |   | 7 | 8 |   |   | 9 | 0 | 7 | 9 |   |   | 1 | 6 | 5 | 4 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| k | 6 | 8 | 6 | 9 | 2 | 2 | 6 | 2 | 2 | 4 | 0 | 1 | 1 | 2 | 1 | 5 | 1 | 2 | 1 | 1 | 1 | 1 | 2 | 4 | 8 | 2 |\n",
      "|   | 4 | 1 | 3 | 5 | 7 | 9 | 3 | 0 | 4 | 1 |   | 2 | 0 | 2 | 7 | 5 | 4 | 2 | 5 | 8 | 0 | 5 | 5 |   | 3 | 2 |\n",
      "|   | 8 |   |   |   | 1 |   |   | 5 | 7 |   |   | 8 | 0 | 1 | 2 |   |   | 3 | 9 | 2 | 2 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| l | 6 | 7 | 7 | 9 | 2 | 1 | 8 | 2 | 2 | 2 | 1 | 0 | 1 | 2 | 1 | 6 | 8 | 2 | 1 | 1 | 1 | 2 | 2 | 3 | 8 | 3 |\n",
      "|   | 3 | 4 | 6 | 9 | 8 | 8 | 2 | 0 | 3 | 1 | 0 |   | 1 | 0 | 8 | 3 |   | 0 | 5 | 7 | 0 | 2 | 7 |   | 0 | 0 |\n",
      "|   | 7 |   |   |   | 8 |   |   | 8 | 4 |   | 0 |   | 3 | 6 | 5 |   |   | 5 | 3 | 1 | 8 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| m | 6 | 6 | 6 | 1 | 2 | 3 | 6 | 2 | 2 | 3 | 9 | 1 | 0 | 2 | 1 | 6 | 1 | 1 | 1 | 1 | 1 | 1 | 3 | 3 | 7 | 2 |\n",
      "|   | 4 | 9 | 5 | 0 | 4 | 3 | 8 | 1 | 5 | 5 | 5 | 4 |   | 2 | 7 | 3 | 5 | 9 | 6 | 7 | 0 | 6 | 2 |   | 6 | 0 |\n",
      "|   | 2 |   |   | 6 | 5 |   |   | 2 | 6 |   |   | 9 |   | 4 | 8 |   |   | 3 | 4 | 3 | 3 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| n | 6 | 7 | 5 | 9 | 2 | 2 | 5 | 1 | 2 | 3 | 1 | 1 | 1 | 0 | 1 | 7 | 2 | 2 | 1 | 1 | 9 | 1 | 3 | 6 | 7 | 3 |\n",
      "|   | 5 | 9 | 1 | 8 | 5 | 6 | 3 | 9 | 3 | 5 | 0 | 2 | 1 |   | 7 | 2 | 8 | 0 | 7 | 4 | 7 | 7 | 4 |   | 7 | 0 |\n",
      "|   | 8 |   |   |   | 1 |   |   | 5 | 6 |   | 9 | 7 | 8 |   | 5 |   |   | 9 | 8 | 5 |   |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| o | 5 | 7 | 6 | 1 | 2 | 3 | 6 | 2 | 2 | 3 | 1 | 1 | 1 | 2 | 0 | 5 | 1 | 1 | 1 | 1 | 9 | 2 | 3 | 4 | 6 | 2 |\n",
      "|   | 9 | 9 | 7 | 0 | 2 | 3 | 4 | 0 | 6 | 5 | 0 | 3 | 1 | 2 |   | 1 | 4 | 9 | 7 | 9 | 6 | 4 | 0 |   | 9 | 8 |\n",
      "|   | 8 |   |   | 2 | 8 |   |   | 3 | 8 |   | 2 | 5 | 6 | 2 |   |   |   | 4 | 4 | 1 |   |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| p | 6 | 7 | 5 | 9 | 2 | 2 | 6 | 2 | 2 | 3 | 1 | 1 | 1 | 2 | 2 | 0 | 1 | 2 | 1 | 1 | 1 | 1 | 4 | 3 | 7 | 2 |\n",
      "|   | 2 | 6 | 7 | 6 | 3 | 6 | 6 | 1 | 4 | 4 | 0 | 2 | 0 | 2 | 0 |   | 5 | 5 | 6 | 8 | 3 | 6 | 1 |   | 5 | 5 |\n",
      "|   | 8 |   |   |   | 8 |   |   | 2 | 4 |   | 8 | 4 | 8 | 0 | 3 |   |   | 0 | 5 | 8 | 7 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| q | 6 | 8 | 6 | 1 | 2 | 3 | 6 | 2 | 2 | 3 | 1 | 1 | 1 | 2 | 1 | 8 | 0 | 2 | 1 | 1 | 1 | 1 | 3 | 9 | 9 | 3 |\n",
      "|   | 8 | 3 | 4 | 2 | 5 | 4 | 0 | 3 | 5 | 8 | 0 | 2 | 3 | 2 | 9 | 3 |   | 2 | 6 | 7 | 0 | 3 | 6 |   | 2 | 0 |\n",
      "|   | 9 |   |   | 1 | 1 |   |   | 0 | 8 |   | 6 | 4 | 6 | 6 | 9 |   |   | 8 | 2 | 8 | 8 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| r | 6 | 6 | 4 | 9 | 2 | 2 | 6 | 1 | 2 | 2 | 8 | 1 | 1 | 1 | 1 | 5 | 2 | 0 | 1 | 1 | 1 | 1 | 3 | 4 | 7 | 2 |\n",
      "|   | 1 | 9 | 3 | 6 | 7 | 8 | 6 | 9 | 2 | 3 | 6 | 0 | 0 | 9 | 8 | 2 | 1 |   | 6 | 5 | 0 | 3 | 3 |   | 5 | 4 |\n",
      "|   | 0 |   |   |   | 5 |   |   | 7 | 1 |   |   | 3 | 5 | 9 | 0 |   |   |   | 3 | 4 | 9 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| s | 6 | 6 | 7 | 1 | 2 | 3 | 7 | 2 | 2 | 3 | 8 | 1 | 1 | 1 | 1 | 5 | 1 | 1 | 0 | 1 | 9 | 2 | 2 | 5 | 8 | 2 |\n",
      "|   | 2 | 0 | 4 | 1 | 3 | 3 | 6 | 3 | 4 | 1 | 9 | 3 | 0 | 9 | 9 | 5 | 3 | 7 |   | 4 | 8 | 1 | 4 |   | 0 | 9 |\n",
      "|   | 3 |   |   | 2 | 9 |   |   | 3 | 9 |   |   | 8 | 7 | 5 | 7 |   |   | 7 |   | 1 |   |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| t | 6 | 7 | 6 | 9 | 2 | 3 | 6 | 1 | 2 | 2 | 9 | 1 | 1 | 2 | 1 | 5 | 1 | 2 | 1 | 0 | 1 | 1 | 3 | 3 | 7 | 3 |\n",
      "|   | 2 | 5 | 4 | 5 | 6 | 3 | 5 | 9 | 6 | 5 | 4 | 3 | 0 | 2 | 8 | 9 | 2 | 1 | 7 |   | 0 | 6 | 1 |   | 7 | 0 |\n",
      "|   | 2 |   |   |   | 0 |   |   | 0 | 2 |   |   | 3 | 0 | 9 | 7 |   |   | 1 | 0 |   | 1 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| u | 6 | 8 | 6 | 1 | 2 | 3 | 6 | 1 | 2 | 3 | 9 | 1 | 9 | 2 | 1 | 5 | 1 | 1 | 1 | 1 | 0 | 1 | 3 | 4 | 8 | 3 |\n",
      "|   | 5 | 0 | 0 | 2 | 2 | 5 | 0 | 9 | 2 | 6 | 2 | 4 | 8 | 1 | 7 | 0 | 7 | 8 | 7 | 7 |   | 5 | 0 |   | 7 | 1 |\n",
      "|   | 1 |   |   | 4 | 0 |   |   | 9 | 1 |   |   | 1 |   | 8 | 7 |   |   | 8 | 6 | 9 |   |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| v | 7 | 9 | 7 | 1 | 2 | 3 | 7 | 1 | 2 | 4 | 1 | 1 | 9 | 2 | 1 | 5 | 9 | 2 | 1 | 1 | 1 | 0 | 3 | 1 | 1 | 3 |\n",
      "|   | 0 | 5 | 9 | 2 | 9 | 7 | 7 | 9 | 5 | 1 | 1 | 4 | 9 | 3 | 8 | 2 |   | 2 | 5 | 8 | 1 |   | 9 | 2 | 0 | 1 |\n",
      "|   | 0 |   |   | 4 | 8 |   |   | 3 | 9 |   | 2 | 3 |   | 3 | 2 |   |   | 1 | 0 | 4 | 0 |   |   |   | 8 |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| w | 6 | 7 | 7 | 1 | 2 | 2 | 6 | 2 | 2 | 2 | 1 | 1 | 9 | 2 | 1 | 6 | 2 | 2 | 1 | 1 | 1 | 1 | 0 | 1 | 9 | 3 |\n",
      "|   | 1 | 4 | 0 | 1 | 5 | 4 | 2 | 0 | 4 | 8 | 2 | 1 | 6 | 0 | 8 | 7 | 0 | 2 | 6 | 9 | 2 | 7 |   |   | 6 | 4 |\n",
      "|   | 6 |   |   | 5 | 8 |   |   | 8 | 9 |   | 0 | 4 |   | 4 | 0 |   |   | 1 | 4 | 0 | 1 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| x | 6 | 9 | 8 | 1 | 2 | 3 | 8 | 2 | 2 | 4 | 1 | 1 | 1 | 2 | 1 | 6 | 1 | 2 | 2 | 1 | 1 | 1 | 5 | 0 | 9 | 3 |\n",
      "|   | 1 | 0 | 0 | 3 | 3 | 8 | 3 | 0 | 9 | 6 | 0 | 3 | 1 | 2 | 9 | 5 | 8 | 3 | 0 | 9 | 1 | 9 | 0 |   | 0 | 2 |\n",
      "|   | 4 |   |   | 9 | 9 |   |   | 1 | 6 |   | 8 | 3 | 1 | 5 | 4 |   |   | 1 | 3 | 1 | 7 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| y | 6 | 6 | 8 | 9 | 2 | 3 | 5 | 1 | 2 | 4 | 1 | 1 | 9 | 2 | 1 | 4 | 1 | 2 | 1 | 1 | 1 | 1 | 2 | 1 | 0 | 3 |\n",
      "|   | 1 | 9 | 2 | 1 | 5 | 3 | 9 | 9 | 3 | 5 | 0 | 3 | 9 | 2 | 6 | 3 | 7 | 0 | 4 | 6 | 0 | 6 | 5 |   |   | 1 |\n",
      "|   | 2 |   |   |   | 5 |   |   | 8 | 1 |   | 1 | 8 |   | 3 | 0 |   |   | 5 | 8 | 4 | 7 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "| z | 6 | 8 | 7 | 1 | 2 | 4 | 6 | 2 | 2 | 4 | 1 | 1 | 1 | 2 | 2 | 6 | 8 | 2 | 1 | 1 | 1 | 2 | 3 | 3 | 7 | 0 |\n",
      "|   | 6 | 6 | 3 | 0 | 6 | 2 | 3 | 3 | 7 | 7 | 1 | 3 | 1 | 1 | 0 | 6 |   | 4 | 6 | 6 | 2 | 2 | 6 |   | 8 |   |\n",
      "|   | 0 |   |   | 5 | 0 |   |   | 1 | 6 |   | 5 | 6 | 7 | 5 | 3 |   |   | 1 | 5 | 4 | 2 |   |   |   |   |   |\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n"
     ]
    }
   ],
   "source": [
    "#Testing a confusion Matrix\n",
    "print_confusionMatrix(substitutionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-folder",
   "metadata": {},
   "source": [
    "## Error Model P(x|w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "presidential-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_model(correctWord, wrongWord):\n",
    "    \n",
    "    errorBeforeEnd, editType, wi, xi = find_edit_type(correctWord, wrongWord)\n",
    "       \n",
    "    #Insertion of xi before wi\n",
    "    if(editType[0]):\n",
    "              \n",
    "        # P(x|w) = ins(wi-1, xi) / count(wi-1)\n",
    "        indexOfInsertedLetter = wrongWord.index(xi) #xi\n",
    "        indexOfInsertedAfter = indexOfInsertedLetter - 1 #wi-1\n",
    "        \n",
    "        Y_AXIS = indexes[correctWord[indexOfInsertedAfter].lower()]\n",
    "        X_AXIS = indexes[wrongWord[indexOfInsertedLetter].lower()]\n",
    " \n",
    "        countWord = unigramsCountForErrorModel[correctWord[indexOfInsertedAfter]]\n",
    "\n",
    "        if(countWord == 0):\n",
    "            return (insertionMatrix[X_AXIS][Y_AXIS] / 0 + len(corpusWords)), xi, \"#\"  \n",
    "        else:  \n",
    "            return (insertionMatrix[X_AXIS][Y_AXIS] / countWord), xi, \"#\"           \n",
    "            \n",
    "    #Deletion of xi before wi\n",
    "    elif(editType[1]):\n",
    "            \n",
    "        # P(x|w) = del(wi-1, wi) / count(wi-1 wi)\n",
    "        indexOfDeletedLetter = correctWord.index(xi) #wi\n",
    "        indexOfDeletedAfter = indexOfDeletedLetter - 1 #wi-1\n",
    "        \n",
    "        Y_AXIS = indexes[correctWord[indexOfDeletedAfter].lower()]\n",
    "        X_AXIS = indexes[correctWord[indexOfDeletedLetter].lower()]\n",
    " \n",
    "        countWord = bigramsCount[correctWord[indexOfDeletedAfter] + correctWord[indexOfDeletedLetter]]\n",
    "\n",
    "        if(countWord == 0):\n",
    "            return (deletionMatrix[X_AXIS][Y_AXIS] / 0 + len(corpusWords)), \"#\", xi  \n",
    "        else:  \n",
    "            return (deletionMatrix[X_AXIS][Y_AXIS] / countWord), \"#\", xi  \n",
    "                    \n",
    "    #Substitution of xi instead of wi\n",
    "    elif(editType[2]):\n",
    "            \n",
    "        # P(x|w) = sub(xi, wi) / count(wi)\n",
    "        indexOfSubstitutedLetter = wrongWord.index(xi) #xi\n",
    "        indexOfSubstitutedAfter = correctWord.index(wi) #wi\n",
    "        \n",
    "        Y_AXIS = indexes[correctWord[indexOfSubstitutedAfter].lower()]\n",
    "        X_AXIS = indexes[wrongWord[indexOfSubstitutedLetter].lower()]\n",
    " \n",
    "        countWord = unigramsCountForErrorModel[correctWord[indexOfSubstitutedAfter]]\n",
    "\n",
    "        if(countWord == 0):\n",
    "            return (substitutionMatrix[X_AXIS][Y_AXIS] / 0 + len(corpusWords)), xi, wi  \n",
    "        else:  \n",
    "            return (substitutionMatrix[X_AXIS][Y_AXIS] / countWord), xi, wi                     \n",
    "                \n",
    "                    \n",
    "    #Transposition of xi with wi\n",
    "    elif(editType[3]):\n",
    "            \n",
    "        # P(x|w) = sub(wi, wi+1) / count(wi wi+1)\n",
    "        indexOfTransposedLetter = correctWord.index(wi) #wi\n",
    "        indexOfTransposedBefore = indexOfTransposedLetter + 1 #wi+1\n",
    "        \n",
    "        Y_AXIS = indexes[correctWord[indexOfTransposedBefore].lower()]\n",
    "        X_AXIS = indexes[correctWord[indexOfTransposedLetter].lower()]\n",
    " \n",
    "        countWord = bigramsCount[correctWord[indexOfTransposedLetter] + correctWord[indexOfTransposedBefore]]\n",
    "\n",
    "        if(countWord == 0):\n",
    "            return (transpositionMatrix[X_AXIS][Y_AXIS] / 0 + len(corpusWords)), xi, wi  \n",
    "        else:  \n",
    "            return (transpositionMatrix[X_AXIS][Y_AXIS] / countWord), xi, wi                \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "packed-message",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.086100475037274e-05, 'w', '#')\n"
     ]
    }
   ],
   "source": [
    "print(error_model(\"martaba\", \"martwaba\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1e9bb",
   "metadata": {},
   "source": [
    "## Generating Candidate Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(correctWord, wrongWord):\n",
    "    \n",
    "    # If both words are of equal length\n",
    "    if(len(correctWord) == len(wrongWord)):\n",
    "        \n",
    "        for index in range(0, len(correctWord)):\n",
    "            \n",
    "            # If an alphabet doesn't match\n",
    "            if(correctWord[index] != wrongWord[index]):\n",
    "                \n",
    "                #Now its either substituted or transposed\n",
    "                \n",
    "                # For Substitution:\n",
    "                tempWord = wrongWord\n",
    "                \n",
    "                tempWord = change_item_string(tempWord, correctWord[index], index)\n",
    "                \n",
    "                if(tempWord == correctWord):\n",
    "                    return 1\n",
    "                    \n",
    "                # For Transposition\n",
    "                tempWord = wrongWord\n",
    "                if(index < len(tempWord)-1):\n",
    "                    tempAlphabet = tempWord[index]\n",
    "                    tempWord = change_item_string(tempWord, tempWord[index+1], index)            \n",
    "                    tempWord = change_item_string(tempWord, tempAlphabet, index+1)\n",
    "\n",
    "                    if(tempWord == correctWord):\n",
    "                        return 1\n",
    "                    \n",
    "    \n",
    "    # If both words are of different length\n",
    "    else:\n",
    "        \n",
    "        ## Checking for last alphabet\n",
    "        \n",
    "        # Check if alphabet inserted at the end\n",
    "        if(wrongWord[:len(wrongWord)-1] == correctWord):\n",
    "            return 1\n",
    "\n",
    "        # Check if alphabet deleted at the end\n",
    "        elif(correctWord[:len(correctWord)-1] == wrongWord):\n",
    "            return 1\n",
    "        \n",
    "        ## Checking before last alphabet\n",
    "        else:\n",
    "            shorterWordLength = min(len(correctWord), len(wrongWord))\n",
    "            \n",
    "            for index in range(0, shorterWordLength):\n",
    "\n",
    "                # If an alphabet doesn't match\n",
    "                if(correctWord[index] != wrongWord[index]):\n",
    "\n",
    "                    # For Deletion\n",
    "                    tempWord = wrongWord\n",
    "                    tempWord = add_item_string(tempWord, correctWord[index], index)\n",
    "\n",
    "                    if(tempWord == correctWord):\n",
    "                        return 1\n",
    "                        \n",
    "                    # For Insertion\n",
    "                    tempWord = wrongWord\n",
    "                    tempWord = remove_item_string(tempWord, index)\n",
    "\n",
    "                    if(tempWord == correctWord):\n",
    "                        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "loving-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindCandidateWords(wrongWord):\n",
    "    \n",
    "    candidateWords = []\n",
    "    \n",
    "    # Checking for 1 edit distance words in vocabulary\n",
    "    for word in totalWords:\n",
    "        \n",
    "        editDistances = edit_distance(word, wrongWord)\n",
    "        if(editDistances == 1):\n",
    "            candidateWords.append(word)\n",
    "            \n",
    "    return candidateWords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fcbe5d",
   "metadata": {},
   "source": [
    "## Selection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "satisfactory-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_correct_word(wrongWord):\n",
    "    \n",
    "    candidateWords = FindCandidateWords(wrongWord)\n",
    "    \n",
    "    candidateProbabilityFromLanguageModel = []\n",
    "    candidateProbabilityFromErrorModel = []\n",
    "    candidateFinalProbability = []\n",
    "    \n",
    "    wrongCharacters = []\n",
    "    correctCharacters = []\n",
    "    \n",
    "    for correctWord in candidateWords:\n",
    "        probability, wrongChar, correctChar = error_model(correctWord, wrongWord)\n",
    "            \n",
    "        candidateProbabilityFromErrorModel.append(probability)\n",
    "        wrongCharacters.append(wrongChar)\n",
    "        correctCharacters.append(correctChar)\n",
    "        candidateProbabilityFromLanguageModel.append(unigrams[correctWord])\n",
    "        \n",
    "        candidateFinalProbability.append((probability * unigrams[correctWord]) * pow(10, 9))\n",
    "        \n",
    "    \n",
    "    print_SelectionModel(candidateWords, wrongCharacters, correctCharacters, candidateProbabilityFromErrorModel, candidateProbabilityFromLanguageModel, candidateFinalProbability)\n",
    "    \n",
    "    return candidateWords, candidateFinalProbability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "varied-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_possible_word(wrongWord):\n",
    "    \n",
    "    candidateWords, candidateFinalProbability = all_possible_correct_word(wrongWord)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    if(candidateFinalProbability):\n",
    "        max_value = max(candidateFinalProbability)\n",
    "    else:\n",
    "        return \"None\"\n",
    "    candidateWord = candidateWords[candidateFinalProbability.index(max_value)]\n",
    "    \n",
    "    return candidateWord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c238cf",
   "metadata": {},
   "source": [
    "## RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f63351d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Wrong Word:hax\n",
      "+------------+-----+------------------------+------------------------+-----------------------+\n",
      "| Candidates | x|w |         P(x|w)         |          P(w)          |   P(x|w)*P(w) *10^9   |\n",
      "+------------+-----+------------------------+------------------------+-----------------------+\n",
      "|    hnx     | a|n | 2.138072237483023e-05  | 1.2636470325508209e-06 |  0.027017686382747156 |\n",
      "|    hab     | x|b | 1.756632948422524e-05  | 6.950058679029515e-07  |  0.01220870206905317  |\n",
      "|    haz     | x|z | 1.794181581268296e-05  | 4.2648087348590207e-07 |  0.007651841279716198 |\n",
      "|    hanx    | #|n | 5.610979564812425e-06  |  6.63414692089181e-07  |  0.003722406280308722 |\n",
      "|    had     | x|d | 3.0866644327210414e-05 | 0.00032210362859720425 |   9.942258140413784   |\n",
      "|    oax     | h|o | 1.750414464967514e-05  | 3.159117581377053e-08  |  0.000552976511097558 |\n",
      "|    haq     | x|q | 1.462189010674792e-05  | 9.737979944594764e-05  |   1.4238767261157985  |\n",
      "|    haj     | x|j | 1.5339576540985516e-05 | 6.950058679029515e-07  |  0.010661095707131394 |\n",
      "|    hay     | x|y | 1.993297205928863e-05  | 7.809338661164073e-05  |   1.5566332933450595  |\n",
      "|    hai     | x|i | 2.1761604853661295e-05 |  0.02151063695423914   |   468.1059815487165   |\n",
      "|    tax     | h|t | 2.1355815287257937e-05 | 1.320511149015608e-05  |  0.28200592183142065  |\n",
      "|     hx     | a|# | 1.2049763273028463e-05 | 3.4750293395147577e-07 |  0.004187328090798129 |\n",
      "|    hau     | x|u | 1.8287710705297605e-05 | 2.3061558344052482e-06 |  0.04217431074093739  |\n",
      "|    hah     | x|h | 1.0764455190572093e-05 | 6.202927371033842e-05  |   0.6677113373586695  |\n",
      "|    hao     | x|o | 2.2194797791091352e-05 | 2.0850176037088547e-06 |  0.04627654410518388  |\n",
      "|    hag     | x|g | 3.070355532373755e-05  | 2.353542598125904e-06  |   0.0722621253683317  |\n",
      "|    hat     | x|t | 2.3577807629284774e-05 | 1.7548898164549525e-05 |   0.4137645450296573  |\n",
      "|    haw     | x|w | 1.4283237164297506e-05 | 5.528455767409842e-07  |  0.007896424487824315 |\n",
      "|    hak     | x|k | 8.203699063099587e-06  |  3.03275287812197e-06  |  0.024879791944861784 |\n",
      "|    han     | x|n | 2.3933644449436825e-05 | 0.00012938166054529717 |   3.096574661768871   |\n",
      "|    fax     | h|f |  2.70166741123334e-05  | 1.5479676148747556e-06 |  0.04182093658751729  |\n",
      "|    hae     | x|e | 2.1990373552959813e-05 | 1.1088502710633454e-05 |   0.2438403167498371  |\n",
      "|    max     | h|m | 1.3452323619858858e-05 | 6.460395453916072e-06  |  0.08690733035834397  |\n",
      "|    bax     | h|b | 1.7761510922938856e-05 | 3.4086878703058394e-05 |   0.6054344684132635  |\n",
      "|    hoax    | #|o | 5.734711116794847e-07  | 1.263647032550821e-07  | 7.246650685274012e-05 |\n",
      "|    ham     | x|m | 1.659119913115926e-05  | 3.4055287527244627e-05 |   0.5650180568333998  |\n",
      "|     ax     | h|# | 0.00015828628713132487 | 2.0534264278950842e-06 |  0.32502924516885207  |\n",
      "|    hav     | x|v | 8.525455214437634e-05  | 2.2113823069639366e-07 |  0.01885304082002082  |\n",
      "|    has     | x|s | 2.4028608010901176e-05 | 2.9790478792385606e-05 |   0.7158237373592983  |\n",
      "|    hap     | x|p | 1.4150007934889066e-05 | 1.1293845353422962e-05 |  0.15980800136634493  |\n",
      "|    haa     | x|a | 1.2762582336843791e-05 | 6.2076660474059076e-06 |  0.07922584904964754  |\n",
      "|    hal     | x|l | 2.4532033024912186e-05 | 0.00011213287855097847 |   2.750847479791071   |\n",
      "|    har     | x|r | 2.6011222885552197e-05 | 0.0013881636520207976  |   36.10783415433509   |\n",
      "|     ha     | x|# | 1.6005192832849708e-05 | 0.0002843521734997485  |   4.5511113693034115  |\n",
      "+------------+-----+------------------------+------------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best Correction for: hax ïs: hai\n"
     ]
    }
   ],
   "source": [
    "wrongWord = input(\"Enter Wrong Word:\")\n",
    "\n",
    "bestWord = best_possible_word(wrongWord)\n",
    "    \n",
    "print(\"Best Correction for:\", wrongWord, \"ïs:\", bestWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "763523ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Wrong Word:humar\n",
      "+------------+-------+------------------------+------------------------+----------------------+\n",
      "| Candidates |  x|w  |         P(x|w)         |          P(w)          |  P(x|w)*P(w) *10^9   |\n",
      "+------------+-------+------------------------+------------------------+----------------------+\n",
      "|    umar    |  h|#  | 2.8826290297408496e-05 | 3.768827274582824e-05  |  1.0864130909791536  |\n",
      "|   humay    |  r|y  | 1.6610810049407192e-05 | 5.844367525547547e-07  | 0.009707967882579424 |\n",
      "|   kumar    |  h|k  | 7.596017651018136e-06  | 3.854123449280004e-06  | 0.02927598974993381  |\n",
      "|   shumar   |  #|s  |          0.0           | 1.1688735051095094e-06 |         0.0          |\n",
      "|   homar    |  u|o  | 2.0249892830016335e-05 | 1.5795587906885263e-06 | 0.03198589623015286  |\n",
      "|   hamar    |  u|a  | 1.3531663031409298e-05 | 2.3693381860327894e-07 | 0.003206108594084626 |\n",
      "|   humor    |  a|o  | 1.475839646933394e-05  | 1.453194087433444e-06  | 0.021446814489234696 |\n",
      "|   humari   |  #|i  | 1.1720622552587503e-05 | 6.618351332984925e-06  | 0.07757119789433066  |\n",
      "|   humary   |  #|y  | 5.0937893972773694e-05 | 8.371661590649189e-07  | 0.04264348104804304  |\n",
      "|   hukar    |  m|k  |  7.21621676846723e-06  | 2.7484322957980357e-06 | 0.01983328321993467  |\n",
      "|   khumar   |  #|k  | 2.4614657536269697e-05 | 2.353542598125904e-06  | 0.057931645049891546 |\n",
      "|   human    |  r|n  | 2.1167978868613013e-05 | 5.8285719376406616e-06 | 0.12337908761016832  |\n",
      "|   humai    |  r|i  | 1.6247684704929547e-05 | 1.579558790688526e-07  | 0.002566417320400698 |\n",
      "|   hunar    |  m|n  | 2.3827272696328217e-05 | 1.750151140082887e-05  | 0.41701328474544674  |\n",
      "|   humare   |  #|e  | 3.5307042261171626e-05 | 8.087341008325255e-06  | 0.28554009076144615  |\n",
      "|   humra    | ar|ra | 1.7601773764710605e-05 | 4.896632251134431e-07  | 0.008618941309345386 |\n",
      "|   humara   |  #|a  | 1.0838481160281084e-05 | 7.313357200887876e-06  | 0.07926568424022926  |\n",
      "|    huma    |  r|#  | 1.4841178808642456e-05 | 6.160279283685252e-07  | 0.009142580636034868 |\n",
      "+------------+-------+------------------------+------------------------+----------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best Correction for: humar ïs: umar\n"
     ]
    }
   ],
   "source": [
    "wrongWord = input(\"Enter Wrong Word:\")\n",
    "\n",
    "bestWord = best_possible_word(wrongWord)\n",
    "    \n",
    "print(\"Best Correction for:\", wrongWord, \"ïs:\", bestWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eae9d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Wrong Word:kaya\n",
      "+------------+-------+------------------------+------------------------+-----------------------+\n",
      "| Candidates |  x|w  |         P(x|w)         |          P(w)          |   P(x|w)*P(w) *10^9   |\n",
      "+------------+-------+------------------------+------------------------+-----------------------+\n",
      "|    aya     |  k|#  |  1.58596910798238e-05  | 5.514239738293645e-05  |   0.8745413878942565  |\n",
      "|   kayam    |  #|m  | 1.730050490442282e-05  | 4.422764613927873e-07  |  0.007651606089436687 |\n",
      "|    kama    |  y|m  | 1.4797555981844743e-05 | 3.190708757190823e-06  |  0.04721469145629347  |\n",
      "|    kaza    |  y|z  | 1.7381134068536616e-05 | 1.9112661367331165e-06 |  0.03321997296321233  |\n",
      "|    kaga    |  y|g  | 2.1825418844584523e-05 |  7.89779395344263e-08  | 0.0017237266098211249 |\n",
      "|    haya    |  k|h  | 1.0978673204314823e-05 | 8.150523359952796e-06  |  0.08948193241305578  |\n",
      "|    gaya    |  k|g  | 2.3305108257776693e-05 | 0.0028844638988521315  |   67.22274342839756   |\n",
      "|    aaya    |  k|a  | 1.3469305137255337e-05 | 0.0008346862517635379  |   11.242643818875024  |\n",
      "|    kaka    |  y|k  | 7.671977827528317e-06  | 2.479907301380986e-06  |  0.01902579383052051  |\n",
      "|    keya    |  a|e  | 1.692982733784354e-05  | 3.996283740441972e-06  |  0.06765639371871413  |\n",
      "|    kaay    | ya|ay | 5.709835667757351e-06  | 9.477352744131157e-08  | 0.0005411412673435808 |\n",
      "|    kyaa    | ay|ya | 1.517156848066723e-05  | 3.2222999330045936e-06 |  0.04888734409882862  |\n",
      "|    paya    |  k|p  | 1.1973083637213824e-05 | 3.073821406679872e-05  |   0.3680312078803636  |\n",
      "|    kasa    |  y|s  | 1.751839401779987e-05  | 1.7059234939436083e-06 |  0.029885039931125963 |\n",
      "|   khaya    |  #|h  | 4.280854903847718e-07  | 6.659419861542827e-05  |  0.028508010171066505 |\n",
      "|   kayak    |  #|k  |          0.0           | 1.4373984995265588e-06 |          0.0          |\n",
      "|    klya    |  a|l  | 2.5454289905547983e-05 | 1.0267132139475421e-06 |  0.026134255797677648 |\n",
      "|    laya    |  k|l  | 2.3609776144276392e-05 | 4.4085485848116766e-05 |   1.0408484520857018  |\n",
      "|   karya    |  #|r  |  4.7477531258332e-06   | 4.422764613927873e-07  | 0.0020998194520600523 |\n",
      "|   kamya    |  #|m  | 1.730050490442282e-05  | 2.2113823069639366e-07 | 0.0038258030447183436 |\n",
      "|    naya    |  k|n  | 2.3508157437002392e-05 | 0.00033053847253948097 |    7.77035045144441   |\n",
      "|    saya    |  k|s  | 1.8820436816420132e-05 | 0.0001071730639482165  |   2.017043878459563   |\n",
      "|    kayo    |  a|o  | 1.475839646933394e-05  | 1.1056911534819683e-07 | 0.0016318228415722052 |\n",
      "|    kay     |  a|#  | 9.722902593303213e-06  | 8.640186585066238e-05  |   0.8400769255456416  |\n",
      "|    zaya    |  k|z  | 1.2334998371219534e-05 | 5.828571937640662e-05  |   0.7189542535733344  |\n",
      "|    kada    |  y|d  | 2.020765923579962e-05  | 2.053426427895084e-07  |  0.004149494152068912 |\n",
      "|    kaha    |  y|h  | 1.0603791680265047e-05 |  0.002813636482677658  |   29.835215126307556  |\n",
      "|    kya     |  a|#  | 9.722902593303213e-06  |  0.009296303715542438  |   90.38705550398187   |\n",
      "|    maya    |  k|m  | 1.494702624428762e-05  | 1.8812545197100348e-05 |  0.28119160678290595  |\n",
      "|    baya    |  k|b  | 1.5809696535802716e-05 | 3.0011617023081997e-07 |  0.004744745576836572 |\n",
      "|    kana    |  y|n  | 2.372090094321961e-05  | 2.843205823239347e-07  |  0.006744340369424571 |\n",
      "|    kala    |  y|l  | 2.5454289905547983e-05 | 0.00023709177448234779 |   6.035002761894484   |\n",
      "|    kiya    |  a|i  | 1.3968597710120426e-05 | 0.00016307364955068344 |   2.2779102076946574  |\n",
      "|    daya    |  k|d  | 2.109590799341719e-05  | 7.629268959025582e-06  |   0.1609463560166374  |\n",
      "|   kayar    |  #|r  |  4.7477531258332e-06   | 3.9488969767213157e-07 |  0.00187483879648219  |\n",
      "|   kraya    |  #|r  | 2.7420298332845863e-05 | 2.843205823239347e-07  |  0.007796155189490751 |\n",
      "|    kara    |  y|r  | 2.3083552777221646e-05 | 1.8228108444545592e-05 |  0.42076950330858776  |\n",
      "|    vaya    |  k|v  | 6.730622537713922e-05  | 4.7386763720655784e-08 | 0.0031894241988757025 |\n",
      "|    kawa    |  y|w  | 7.141618582148753e-06  | 2.2113823069639366e-07 | 0.0015792848975648627 |\n",
      "|    yaya    |  k|y  | 1.8382629788010626e-05 | 1.2478514446439356e-06 |  0.022938791137323705 |\n",
      "|    kayi    |  a|i  | 1.3968597710120426e-05 | 0.0005555308266851546  |   7.759986633535559   |\n",
      "|    kaye    |  a|e  | 1.692982733784354e-05  | 4.106852855790168e-07  |  0.00695283097504572  |\n",
      "|    kata    |  y|t  | 2.0244819116244516e-05 | 6.397213102288531e-06  |  0.12951042210390076  |\n",
      "|    kaa     |  y|#  | 1.504903845582232e-05  | 1.4879443808285918e-05 |  0.22392132207214208  |\n",
      "|    kaia    |  y|i  | 1.698287405809378e-05  | 1.690127906036723e-06  |  0.028703229370291426 |\n",
      "|    jaya    |  k|j  | 1.3672231264791436e-05 | 3.0580258187729865e-05 |   0.4181003620796746  |\n",
      "|    raya    |  k|r  | 2.511040131375818e-05  | 1.8954705488262313e-07 |  0.004759602615943614 |\n",
      "|    kayl    |  a|l  | 2.5454289905547983e-05 | 7.581882195304925e-07  |  0.019299142742900413 |\n",
      "|    taya    |  k|t  | 2.2466811458271353e-05 | 1.2873404144111489e-05 |  0.28922434373188194  |\n",
      "+------------+-------+------------------------+------------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best Correction for: kaya ïs: kya\n"
     ]
    }
   ],
   "source": [
    "wrongWord = input(\"Enter Wrong Word:\")\n",
    "\n",
    "bestWord = best_possible_word(wrongWord)\n",
    "    \n",
    "print(\"Best Correction for:\", wrongWord, \"ïs:\", bestWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04ebddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Wrong Word:asdfasdfas\n",
      "+------------+-----+--------+------+-------------------+\n",
      "| Candidates | x|w | P(x|w) | P(w) | P(x|w)*P(w) *10^9 |\n",
      "+------------+-----+--------+------+-------------------+\n",
      "+------------+-----+--------+------+-------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best Correction for: asdfasdfas ïs: None\n"
     ]
    }
   ],
   "source": [
    "wrongWord = input(\"Enter Wrong Word:\")\n",
    "\n",
    "bestWord = best_possible_word(wrongWord)\n",
    "    \n",
    "print(\"Best Correction for:\", wrongWord, \"ïs:\", bestWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f58e7f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Wrong Word:hampe\n",
      "+------------+-----+------------------------+------------------------+-----------------------+\n",
      "| Candidates | x|w |         P(x|w)         |          P(w)          |   P(x|w)*P(w) *10^9   |\n",
      "+------------+-----+------------------------+------------------------+-----------------------+\n",
      "|   sampe    | h|s | 1.751839401779987e-05  | 2.3693381860327894e-07 |  0.004150699990434161 |\n",
      "|   hamle    | p|l | 2.2871970639767755e-05 | 6.160279283685252e-07  |  0.014089772690921862 |\n",
      "|   hamre    | p|r | 2.8150674118562983e-05 | 6.318235162754104e-07  |  0.017786257907113655 |\n",
      "|   hamne    | p|n | 2.3401785683893784e-05 | 1.6111499665022968e-06 |   0.0377037862206994  |\n",
      "|   humpe    | a|u | 1.5474216750636436e-05 | 3.317073460445905e-07  |  0.00513291137047236  |\n",
      "|    hame    | p|# | 1.8235372018030897e-05 | 1.4610918813868867e-05 |   0.2664355400961455  |\n",
      "|    ampe    | h|# | 2.9535187910042257e-05 | 1.263647032550821e-07  | 0.0037322052558355786 |\n",
      "|   hamse    | p|s | 1.9530641979303913e-05 | 7.739838074373778e-07  |  0.015116400640837928 |\n",
      "|    hamp    | e|# | 1.6980009521866877e-05 | 1.4216029116196736e-07 | 0.0024138830975615733 |\n",
      "+------------+-----+------------------------+------------------------+-----------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best Correction for: hampe ïs: hame\n"
     ]
    }
   ],
   "source": [
    "wrongWord = input(\"Enter Wrong Word:\")\n",
    "\n",
    "bestWord = best_possible_word(wrongWord)\n",
    "    \n",
    "print(\"Best Correction for:\", wrongWord, \"ïs:\", bestWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b00d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
